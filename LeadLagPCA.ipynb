{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e0a180f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numba\n",
    "from numba import njit\n",
    "from numba.typed import Dict\n",
    "from numba.typed import List\n",
    "import tensorly as tl\n",
    "from tensorly.decomposition import parafac\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120faedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def process_pair(fuck8, n, x, total_pairs, tensor, date_index):\n",
    "    for index in range(total_pairs):\n",
    "        i = x[index // n]\n",
    "        j = x[index % n]\n",
    "        x1 = x.index(i)\n",
    "        y1 = x.index(j)\n",
    "        fuck10_values = np.array(\n",
    "            [fuck8[f\"{i}r\"], fuck8[f\"{j}ryi\"], fuck8[f\"{j}rys\"]])\n",
    "        if (np.isnan(fuck10_values[0]) or np.isnan(fuck10_values[1]) or np.isnan(fuck10_values[2])):\n",
    "            continue\n",
    "        if (fuck10_values[0] >= 0):\n",
    "            if fuck10_values[0] <= fuck10_values[1] and fuck10_values[0] <= fuck10_values[2]:\n",
    "                tensor[x1, y1, date_index] = 1\n",
    "        if (fuck10_values[0] < 0):\n",
    "            if fuck10_values[0] <= fuck10_values[2] and fuck10_values[0] <= fuck10_values[1]:\n",
    "                tensor[x1, y1, date_index] = 1\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255dc26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fuck7 = pd.read_csv(\"finally.csv\")\n",
    "fuck7['datadate'] = pd.to_datetime(fuck7['datadate'])\n",
    "fuck7 = fuck7.sort_values(by='datadate')\n",
    "start_date = datetime.strptime(\"2013-03-15\", \"%Y-%m-%d\")\n",
    "end_date = datetime.strptime(\"2023-03-15\", \"%Y-%m-%d\")\n",
    "date_range = pd.date_range(start_date, end_date, freq='D')\n",
    "\n",
    "with open(\"newstocks.txt\", \"r\") as f:\n",
    "    x = f.read().splitlines()\n",
    "x[0] = \"A\"\n",
    "\n",
    "n = len(x)\n",
    "total_pairs = n * n\n",
    "typed_x = List(x)\n",
    "tensor = np.zeros((n, n, len(date_range)), dtype=np.int64)\n",
    "\n",
    "for date_index, date in enumerate(date_range):\n",
    "    typed_dict = Dict.empty(\n",
    "        key_type=numba.types.unicode_type,\n",
    "        value_type=numba.types.float64)\n",
    "    fuck8 = fuck7[fuck7[\"datadate\"] == date]\n",
    "\n",
    "    if not fuck8.empty:\n",
    "        fuck8 = fuck8.drop(\"datadate\", axis=1)\n",
    "        fuck8 = fuck8.drop(\"Unnamed: 0\", axis=1)\n",
    "        fuck8 = fuck8.to_dict()\n",
    "        for key, value in fuck8.items():\n",
    "            typed_dict[key] = value[3328]\n",
    "        tensor = process_pair(typed_dict, n, typed_x, total_pairs, tensor, date_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0719b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform Tensor PCA\n",
    "tl.set_backend('numpy') \n",
    "# parameter that determines the number of factors/components we want to\n",
    "# extract from the tensor decomposition.\n",
    "rank = 10\n",
    "# Tensor PCA using PARAFAC (Parallel Factors Analysis) method\n",
    "# decomposes the input tensor into a sum of rank-1 tensors\n",
    "factors = parafac(tensor, rank)\n",
    "\n",
    "# returns a list of factors, one for each mode (dimension) of the input tensor\n",
    "# In our case, we have three modes: stock symbols (rows), stock symbols (columns), and dates (depth)\n",
    "# Each factor is a 2D matrix where the number of rows corresponds to the size of the corresponding mode,\n",
    "# and the number of columns is equal to the specified rank\n",
    "for i, factor in enumerate(factors):\n",
    "    print(f\"Factor {i + 1}:\")\n",
    "    print(factor)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d60842",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, factor in enumerate(factors):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    for j in range(rank):\n",
    "        plt.plot(factor[:, j], label=f\"Component {j + 1}\")\n",
    "    plt.title(f\"Factor {i + 1}\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Calculate the explained variance ratio for each factor\n",
    "explained_variances = []\n",
    "total_variance = tl.norm(tensor, 2) ** 2\n",
    "\n",
    "for component in range(rank):\n",
    "    component_tensors = tl.kruskal_to_tensor((factors[0][:, component], factors[1][:, component], factors[2][:, component]))\n",
    "    component_variance = tl.norm(component_tensors, 2) ** 2\n",
    "    explained_variances.append(component_variance / total_variance)\n",
    "\n",
    "for i, explained_variance in enumerate(explained_variances):\n",
    "    print(f\"Component {i + 1}: {explained_variance * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
